{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/8Chatea8/HeadChecker/blob/main/model/20230904_Mahi_Mahi_data_whole_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ijc8cqiWkRrC",
      "metadata": {
        "id": "ijc8cqiWkRrC"
      },
      "source": [
        "## 2023.09.04.\n",
        "담당: 노유현  \n",
        "데이터: train: data_whole.csv  \n",
        "모델: 'bert-base-multilingual-cased'  \n",
        "파라미터: MAX_LEN = 450/batch_size = 8/epoch=4  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69b268a",
      "metadata": {
        "id": "c69b268a",
        "outputId": "0f3958af-3ab3-45f0-8c2e-d09fe85b76ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (3.12.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: tensorflow in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (4.24.2)\n",
            "Requirement already satisfied: setuptools in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "filelock 3.12.3 requires typing-extensions>=4.7.1; python_version < \"3.11\", but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n",
            "Requirement already satisfied: torch in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
            "Requirement already satisfied: wheel in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: cmake in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting typing-extensions (from torch)\n",
            "  Obtaining dependency information for typing-extensions from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.7.1\n",
            "Requirement already satisfied: scikit-learn in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: pandas in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face의 트랜스포머 모델 및 라이브러리 설치\n",
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "!pip install torch\n",
        "!pip install -U scikit-learn\n",
        "!pip install pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8416ce0",
      "metadata": {
        "id": "b8416ce0",
        "outputId": "5a5ea409-30c6-46ad-d91f-183092f39f97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:35:00.294877: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-09-04 14:35:00.401415: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-04 14:35:00.882383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2650b8",
      "metadata": {
        "id": "ab2650b8"
      },
      "outputs": [],
      "source": [
        "# 메모리 삭제 : CUDA out of memery\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08339d47-9cca-4b6d-a373-d4adcd942f35",
      "metadata": {
        "id": "08339d47-9cca-4b6d-a373-d4adcd942f35"
      },
      "outputs": [],
      "source": [
        "#### \"CUDA 메모리 부족\"\n",
        "\n",
        "# 1.배치 크기 줄이기:  batch_size 매개변수를 수정\n",
        "# 2.메모리 해제:  torch.cuda.empty_cache()\n",
        "# 3.시퀀스 길이 제한: 입력 시퀀스를 자르거나 작은 부분으로 나눈다. BERT와 같은 모델은 메모리 사용량에 시퀀스 길이의 제곱 종속성이 있음\n",
        "# 4.기울기 클리핑 사용: 최적화 단계에서 기울기 클리핑을 적용\n",
        "# 5.모델 크기 감소: 위의 솔루션 중 어느 것도 도움이 되지 않는 경우, 더 작은 모델 버전을 사용하거나 메모리 사용량이 더 적은 다른 모델 아키텍처를 고려"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로드"
      ],
      "metadata": {
        "id": "8AJjwm5lyXiM"
      },
      "id": "8AJjwm5lyXiM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82395c6a",
      "metadata": {
        "id": "82395c6a",
        "outputId": "a7c19dbb-78a8-48e6-f51e-5aaea2d1c6a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Content</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>광주지역 소상공인의 외침... 코로나 직격탄 맞은 소상공인 도울 방법은?</td>\n",
              "      <td>신종 코로나바이러스 감염증 직격탄을 맞은 소상공인들이 저마다 절박한 심정으로 지원을...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“과일 껍질 세척 후 드세요”…경기보건환경硏, 과일 껍질 잔류농약 검출률 과육의 10배</td>\n",
              "      <td>경기도보건환경연구원은 지난해 1월부터 8월까지 온라인 및 도내 대형마트에서 유통된 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>늙은 부모님 악몽 꾼다면…이 병 걸릴 확률 높다</td>\n",
              "      <td>노년에 악몽을 자주 꾸는 것은 파킨슨병을 예고하는 경고 신호일 수 있다는 연구 결과...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13세 친딸 몸쓸짓하고 “친구 소개해줘… 40대父 징역 12년</td>\n",
              "      <td>13세 친딸을 수차례 성폭행하고 학대한 혐의로 재판에 넘겨진 40대 남성에게 법원이...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>경과원, 인공지능?가상현실 기술 성과공유회 개최</td>\n",
              "      <td>경기도경제과학진흥원은 16일부터 이틀간 경기창조경제혁신센터 국제회의장에서‘2021 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Headline  \\\n",
              "0          광주지역 소상공인의 외침... 코로나 직격탄 맞은 소상공인 도울 방법은?   \n",
              "1  “과일 껍질 세척 후 드세요”…경기보건환경硏, 과일 껍질 잔류농약 검출률 과육의 10배   \n",
              "2                        늙은 부모님 악몽 꾼다면…이 병 걸릴 확률 높다   \n",
              "3                13세 친딸 몸쓸짓하고 “친구 소개해줘… 40대父 징역 12년   \n",
              "4                        경과원, 인공지능?가상현실 기술 성과공유회 개최   \n",
              "\n",
              "                                             Content  Class  \n",
              "0  신종 코로나바이러스 감염증 직격탄을 맞은 소상공인들이 저마다 절박한 심정으로 지원을...      0  \n",
              "1  경기도보건환경연구원은 지난해 1월부터 8월까지 온라인 및 도내 대형마트에서 유통된 ...      1  \n",
              "2  노년에 악몽을 자주 꾸는 것은 파킨슨병을 예고하는 경고 신호일 수 있다는 연구 결과...      1  \n",
              "3  13세 친딸을 수차례 성폭행하고 학대한 혐의로 재판에 넘겨진 40대 남성에게 법원이...      1  \n",
              "4  경기도경제과학진흥원은 16일부터 이틀간 경기창조경제혁신센터 국제회의장에서‘2021 ...      1  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "df = pd.read_csv('/home/hyunkoo/DATA/Uhyeon/data_whole.csv', encoding='utf-8')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a86bc7",
      "metadata": {
        "id": "58a86bc7",
        "outputId": "78e43a94-8a1c-4210-cec2-23a752ef3a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(318132, 3)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d2f4b2",
      "metadata": {
        "id": "31d2f4b2",
        "outputId": "a6ae8f29-933a-4c85-83ec-2eadb1fd1a04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "1    162468\n",
              "0    155664\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Class'].value_counts() # 진짜뉴스 1: 41,332개 / 낚시뉴스 0: 29,663개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c364a6d-eca3-4202-a9e3-999540722762",
      "metadata": {
        "id": "9c364a6d-eca3-4202-a9e3-999540722762",
        "outputId": "8b6396fa-8a19-4779-a8c5-ac5113c289e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 데이터의 인덱스 (첫 5개): Index([0, 6, 12, 17, 20], dtype='int64')\n",
            "Class 1 데이터의 인덱스 (첫 5개): Index([1, 2, 3, 4, 5], dtype='int64')\n"
          ]
        }
      ],
      "source": [
        "# Class가 0인 데이터의 인덱스 출력 (첫 5개)\n",
        "class_0_indices = df[df['Class'] == 0].index[:5]\n",
        "\n",
        "# Class가 1인 데이터의 인덱스 출력 (첫 5개)\n",
        "class_1_indices = df[df['Class'] == 1].index[:5]\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Class 0 데이터의 인덱스 (첫 5개):\", class_0_indices)\n",
        "print(\"Class 1 데이터의 인덱스 (첫 5개):\", class_1_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리\n",
        "\n",
        "1. 특수토큰 삽입 [CLS] + 헤드라인 + [SEP] + 본문 + [SEP]\n",
        "2. 토크나이징(BertTokenizer.from_pretrained('bert-base-multilingual-cased' 사용))\n",
        "3. MAX_LEN에 맞게 패딩\n",
        "4. 패딩에 맞게 어텐션 마스크 만듦\n",
        "5. train, validation으로 나눔(9:1)\n",
        "6. Dataloader에 피딩"
      ],
      "metadata": {
        "id": "XDi0iaDgycf_"
      },
      "id": "XDi0iaDgycf_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fae7626",
      "metadata": {
        "id": "7fae7626",
        "outputId": "2bc5d747-6f0e-4b67-e36c-249366dbcfae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            광주지역 소상공인의 외침... 코로나 직격탄 맞은 소상공인 도울 방법은?\n",
              "1    “과일 껍질 세척 후 드세요”…경기보건환경硏, 과일 껍질 잔류농약 검출률 과육의 10배\n",
              "2                          늙은 부모님 악몽 꾼다면…이 병 걸릴 확률 높다\n",
              "3                  13세 친딸 몸쓸짓하고 “친구 소개해줘… 40대父 징역 12년\n",
              "4                          경과원, 인공지능?가상현실 기술 성과공유회 개최\n",
              "Name: Headline, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 헤드라인 데이터 전처리\n",
        "\n",
        "sentences_h = df['Headline']\n",
        "sentences_h.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7886d57d",
      "metadata": {
        "id": "7886d57d",
        "outputId": "e7b7154d-d33d-430c-9e5e-ef0dc3452278"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS] 광주지역 소상공인의 외침... 코로나 직격탄 맞은 소상공인 도울 방법은? [SEP]',\n",
              " '[CLS] “과일 껍질 세척 후 드세요”…경기보건환경硏, 과일 껍질 잔류농약 검출률 과육의 10배 [SEP]',\n",
              " '[CLS] 늙은 부모님 악몽 꾼다면…이 병 걸릴 확률 높다 [SEP]',\n",
              " '[CLS] 13세 친딸 몸쓸짓하고 “친구 소개해줘… 40대父 징역 12년 [SEP]',\n",
              " '[CLS] 경과원, 인공지능?가상현실 기술 성과공유회 개최 [SEP]']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 헤드라인 BERT의 입력 형식에 맞게 변환\n",
        "sentences_h = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences_h]\n",
        "sentences_h[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5eabd62",
      "metadata": {
        "id": "b5eabd62",
        "outputId": "7e46af87-9d5f-47df-a4c7-d4a4d1b38fb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    신종 코로나바이러스 감염증 직격탄을 맞은 소상공인들이 저마다 절박한 심정으로 지원을...\n",
              "1    경기도보건환경연구원은 지난해 1월부터 8월까지 온라인 및 도내 대형마트에서 유통된 ...\n",
              "2    노년에 악몽을 자주 꾸는 것은 파킨슨병을 예고하는 경고 신호일 수 있다는 연구 결과...\n",
              "3    13세 친딸을 수차례 성폭행하고 학대한 혐의로 재판에 넘겨진 40대 남성에게 법원이...\n",
              "4    경기도경제과학진흥원은 16일부터 이틀간 경기창조경제혁신센터 국제회의장에서‘2021 ...\n",
              "Name: Content, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 본문 데이터 전처리\n",
        "\n",
        "sentences_c = df['Content']\n",
        "sentences_c[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c2c00c0",
      "metadata": {
        "id": "0c2c00c0",
        "outputId": "0da396a4-0f1b-4fa3-835a-e5cc13c436e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['신종 코로나바이러스 감염증 직격탄을 맞은 소상공인들이 저마다 절박한 심정으로 지원을 호소했다.\\n광주시는 10일 시청 중회의실에서 지역 소상공업종 대표들과 간담회를 하고 건의 사항을 청취했다.\\n이날 간담회에는 상인연합회를 비롯해 학원, 노래연습장, 예식업, 단란주점, 제과점, 휴게음식점, 목욕탕, 숙박, 세탁, 이미용업 등 업종 대표 14명이 참석했다.\\n소상공인들은 매출 감소와 각종 제한에 따른 어려움을 토로하고 지원을 요청했다.\\n예식업 대표는 매출 규모를 기준으로 하다 보니 재난 지원금과 시 지원 대상에서 제외됐다고 고충을 털어놨다.\\n목욕업 대표는 손님이 없어도 물을 데워야 하는 특성상 공공요금 부담이 크다 면서 기본요금 감면 등 실질적인 지원이 필요하다고 호소했다.\\n70세 이상 기초생활보장 수급자, 차상위 계층 노인을 위한 경로 목욕비 바우처 사업도 제안됐다.\\n세탁업 대표는 사업자 등록을 하지 않은 업소들은 영업 신고증이 있어도 정부 지원에서 누락되는 경우가 많다며 지원을 호소했다.\\n숙박업 대표는 연 매출 4억원 이상 사업자를 지원에서 제외하는 문제점을 지적하고 착한 임대료 운동을 확산시켜달라고 건의했다.\\n이용섭 광주시장은 미디어SR에 코로나19라는 사회 재난으로 큰 어려움을 겪는 소상공인들의 심정을 충분히 이해한다 며 소상공인이 행복해야 광주가 행복하다는 마음으로 간담회에서 나온 의견을 정책에 반영해 지원 대책을 강구하겠다고 밝혔다. [SEP]',\n",
              " '경기도보건환경연구원은 지난해 1월부터 8월까지 온라인 및 도내 대형마트에서 유통된 과일류 등 20품목 114건에 대한 잔류 농약 함량을 조사한 결과 껍질의 잔류농약 검출률이 과육의 10배 이상인 것으로 나타났다고 3일 밝혔다.\\n이에 따라 연구원은 껍질에서 검출된 농약 성분이 대부분 기준치 이내이지만 껍질을 세척 후 섭취할 것을 권장했다.\\n식품 안전을 위한 과일 잔류 농약 검사는 꼭지만 제거 후 껍질과 과육을 함께 갈아서 진행하는데, 이번 연구원의 검사는 기존 방식과 과피·과육 분리 방식을 병행했다.\\n기존 방식 검사에서는 114건 중 48건의 시료에서 22종의 농약 성분이 검출됐으나 모두 기준치 이내였다.\\n같은 과일 시료를 과피와 과육으로 분리해 과피만 검사한 결과 114건 중 85건에서 46종의 농약 성분이 기준치 이내로 검출됐다.\\n과육만을 대상으로 검사했을 때는 114건 중 8건에서 5종의 농약 성분이 기준치 이내로 검출됐다.\\n경기도보건환경연구원 관계자는 “과일을 흐르는 물, 주방용 세제, 식초 물 등으로 세척 시 잔류량이 최대 10분의 1로 감소한다”며 “과일을 세척 후에 섭취하길 권장한다”고 말했다. [SEP]',\n",
              " '노년에 악몽을 자주 꾸는 것은 파킨슨병을 예고하는 경고 신호일 수 있다는 연구 결과가 나왔다.\\n일간 텔레그래프 인터넷판에 따르면 영국 버밍엄 대학 인간 뇌 건강 센터의 아비데미 오타이쿠 박사 연구팀이 67세 이상 노인 3818명을 대상으로 최장 12년 간 진행된 조사 자료를 분석한 결과 이 같은 사실이 밝혀졌다.\\n연구 결과 악몽을 자주 꾸는 노인은 파킨슨병 발병률이 4.3%로 악몽을 꾸지 않는 노인의 2.2%보다 거의 2배 높았다.\\n대부분 연구가 시작된 첫 5년 사이에 발병해 연구 기간 내 91명이 파킨슨병 진단을 받았다.\\n연구팀은 이 결과가 “언젠가 파킨슨병 진단을 받게 될 사람은 파킨슨병 증상이 나타나기 몇 년 전부터 악몽과 사나운 꿈을 꾸기 시작할 수 있다”고 시사하는 것이라며, 파킨슨병 증상이 나타나기 전 초기 단계에서 수면 중 부정적인 감정을 억압하는 뇌 부위들의 퇴행이 시작되기 때문일 수 있다고 추정했다.\\n급속안구운동 수면장애가 파킨슨병 발병률 증가와 연관이 있다는 연구 결과도 있다.\\n렘수면은 꿈을 꾸는 수면으로 몸은 마비 상태이나 뇌는 활발히 활동한다.\\n비 렘수면은 몸은 움직일 수 있지만 뇌는 활동하지 않는 상태다.\\n렘수면 장애는 꿈꾸는 내용대로 행동하는 것이다.\\n옆에서 자는 사람을 때리거나 발로 찰 수 있으며 침대에서 떨어져 다칠 수도 있다.\\n렘수면 장애의 70%는 파킨슨병으로 이어질 수 있다.\\n이 연구 결과는 영국의 의학 전문지 랜싯의 자매지 ‘e임상의학’ 최신호에 게재됐다. [SEP]',\n",
              " '13세 친딸을 수차례 성폭행하고 학대한 혐의로 재판에 넘겨진 40대 남성에게 법원이 징역 12년형을 선고했다.\\n8일 법조계에 따르면 대구지방법원 포항지원 제1형사부는 성폭력 범죄의 처벌 등에 관한 특례법 위반 등으로 기소된 A씨에게 징역 12년을 선고했다고 밝혔다.\\n또, 아동·청소년시설과 장애인복지시설 취업제한 7년과 함께 같은 기간 동안 위치추적 전자장치 부착도 명령했다.\\nA씨는 지난 2018년부터 2020년까지 자신의 딸인 B양을 수차례 강간하고 평소 대답을 잘 하지 않는다는 이유로 학대한 혐의를 받고 있다.\\nA씨가 경제적 지위를 내세워 범행 당시 13세에 불과했던 B양을 협박해 성적 대상자로 삼은 것으로 알려졌다.\\nA씨는 B양이 어머니와 여동생과 함께 자고 있는 상황에서도 성폭력을 행사했다.\\n심지어 A씨는 B양에게 “친구를 소개해 달라”고 요구한 것으로 조사됐다.\\n재판부는 “범행이 장기간에 걸쳐 반복적으로 이뤄지면서 어린 피해자가 오랜 기간 극심한 정신적, 심리적 고통과 성적 수치심에 시달린 것으로 보인다”며 “죄질이 매우 무거워 엄벌이 불가피하나, 피고인이 공소 사실을 모두 인정하고 자신의 잘못을 뉘우친 모습을 보이는 점 등을 참작했다”고 양형 이유를 밝혔다. [SEP]',\n",
              " '경기도경제과학진흥원은 16일부터 이틀간 경기창조경제혁신센터 국제회의장에서‘2021 성과공유회 가상현실과 인공지능의 만남’ 행사를 개최한다고 15일 밝혔다.\\n이번 행사는 경기도의 VR·AR, AI 실증과제에 대한 지원성과를 공유하고 기술교류를 통한 협업 비즈니스 모델 창출기회 제공하기 위해 마련됐다.\\n코로나19 방역수칙을 준수하여 온·오프라인으로 동시 개최한다. 1일 차인 16일에는 개회식을 시작으로 VR·AR, AI 기술 실증기업의 우수과제 성과공유와 Pitching, 소프트웨어정책연구소 이승환 팀장의 ‘메타버스 비긴즈’ 특별강연으로 진행된다.\\n또 이날 오전 11시부터 개방되는 전시장에는 ‘가상현실과 인공지능의 만남’이라는 주제에 맞춰 경기도에서 지원한 13개 VR·AR 기업과 과기정통부가 지원하고 정보통신산업진흥원을 전담기관으로 지원하는 7개 AI 기업이 전시 및 체험부스를 운영한다. 2일 차인 17일에는 정용찬 정보통신정책연구원 본부장이 ‘메타버스 시대 데이터 거버넌스’ 란 주제로 강연한다.\\n또 민옥기 한국전자통신연구원 본부장이 ‘인공지능 기술현황과 전망’에 대해 특별강연한다.\\n유승경 경과원 원장은 “이번 성과공유회를 통해 경기 도내 VR·AR과 인공지능의 기술적 성과를 직접 체험하고, 이를 통해 관련 산업에 대한 이해도를 높이는 계기가 될 것으로 기대된다”고 말했다. [SEP]']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences_c = [ str(sentence) + \" [SEP]\" for sentence in sentences_c]\n",
        "sentences_c[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e272bf5",
      "metadata": {
        "id": "0e272bf5",
        "outputId": "789796d3-aa80-4d9b-9df2-875dd0cbf3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 광주지역 소상공인의 외침... 코로나 직격탄 맞은 소상공인 도울 방법은? [SEP] 신종 코로나바이러스 감염증 직격탄을 맞은 소상공인들이 저마다 절박한 심정으로 지원을 호소했다.\n",
            "광주시는 10일 시청 중회의실에서 지역 소상공업종 대표들과 간담회를 하고 건의 사항을 청취했다.\n",
            "이날 간담회에는 상인연합회를 비롯해 학원, 노래연습장, 예식업, 단란주점, 제과점, 휴게음식점, 목욕탕, 숙박, 세탁, 이미용업 등 업종 대표 14명이 참석했다.\n",
            "소상공인들은 매출 감소와 각종 제한에 따른 어려움을 토로하고 지원을 요청했다.\n",
            "예식업 대표는 매출 규모를 기준으로 하다 보니 재난 지원금과 시 지원 대상에서 제외됐다고 고충을 털어놨다.\n",
            "목욕업 대표는 손님이 없어도 물을 데워야 하는 특성상 공공요금 부담이 크다 면서 기본요금 감면 등 실질적인 지원이 필요하다고 호소했다.\n",
            "70세 이상 기초생활보장 수급자, 차상위 계층 노인을 위한 경로 목욕비 바우처 사업도 제안됐다.\n",
            "세탁업 대표는 사업자 등록을 하지 않은 업소들은 영업 신고증이 있어도 정부 지원에서 누락되는 경우가 많다며 지원을 호소했다.\n",
            "숙박업 대표는 연 매출 4억원 이상 사업자를 지원에서 제외하는 문제점을 지적하고 착한 임대료 운동을 확산시켜달라고 건의했다.\n",
            "이용섭 광주시장은 미디어SR에 코로나19라는 사회 재난으로 큰 어려움을 겪는 소상공인들의 심정을 충분히 이해한다 며 소상공인이 행복해야 광주가 행복하다는 마음으로 간담회에서 나온 의견을 정책에 반영해 지원 대책을 강구하겠다고 밝혔다. [SEP]\n",
            "[CLS] “과일 껍질 세척 후 드세요”…경기보건환경硏, 과일 껍질 잔류농약 검출률 과육의 10배 [SEP] 경기도보건환경연구원은 지난해 1월부터 8월까지 온라인 및 도내 대형마트에서 유통된 과일류 등 20품목 114건에 대한 잔류 농약 함량을 조사한 결과 껍질의 잔류농약 검출률이 과육의 10배 이상인 것으로 나타났다고 3일 밝혔다.\n",
            "이에 따라 연구원은 껍질에서 검출된 농약 성분이 대부분 기준치 이내이지만 껍질을 세척 후 섭취할 것을 권장했다.\n",
            "식품 안전을 위한 과일 잔류 농약 검사는 꼭지만 제거 후 껍질과 과육을 함께 갈아서 진행하는데, 이번 연구원의 검사는 기존 방식과 과피·과육 분리 방식을 병행했다.\n",
            "기존 방식 검사에서는 114건 중 48건의 시료에서 22종의 농약 성분이 검출됐으나 모두 기준치 이내였다.\n",
            "같은 과일 시료를 과피와 과육으로 분리해 과피만 검사한 결과 114건 중 85건에서 46종의 농약 성분이 기준치 이내로 검출됐다.\n",
            "과육만을 대상으로 검사했을 때는 114건 중 8건에서 5종의 농약 성분이 기준치 이내로 검출됐다.\n",
            "경기도보건환경연구원 관계자는 “과일을 흐르는 물, 주방용 세제, 식초 물 등으로 세척 시 잔류량이 최대 10분의 1로 감소한다”며 “과일을 세척 후에 섭취하길 권장한다”고 말했다. [SEP]\n",
            "[CLS] 늙은 부모님 악몽 꾼다면…이 병 걸릴 확률 높다 [SEP] 노년에 악몽을 자주 꾸는 것은 파킨슨병을 예고하는 경고 신호일 수 있다는 연구 결과가 나왔다.\n",
            "일간 텔레그래프 인터넷판에 따르면 영국 버밍엄 대학 인간 뇌 건강 센터의 아비데미 오타이쿠 박사 연구팀이 67세 이상 노인 3818명을 대상으로 최장 12년 간 진행된 조사 자료를 분석한 결과 이 같은 사실이 밝혀졌다.\n",
            "연구 결과 악몽을 자주 꾸는 노인은 파킨슨병 발병률이 4.3%로 악몽을 꾸지 않는 노인의 2.2%보다 거의 2배 높았다.\n",
            "대부분 연구가 시작된 첫 5년 사이에 발병해 연구 기간 내 91명이 파킨슨병 진단을 받았다.\n",
            "연구팀은 이 결과가 “언젠가 파킨슨병 진단을 받게 될 사람은 파킨슨병 증상이 나타나기 몇 년 전부터 악몽과 사나운 꿈을 꾸기 시작할 수 있다”고 시사하는 것이라며, 파킨슨병 증상이 나타나기 전 초기 단계에서 수면 중 부정적인 감정을 억압하는 뇌 부위들의 퇴행이 시작되기 때문일 수 있다고 추정했다.\n",
            "급속안구운동 수면장애가 파킨슨병 발병률 증가와 연관이 있다는 연구 결과도 있다.\n",
            "렘수면은 꿈을 꾸는 수면으로 몸은 마비 상태이나 뇌는 활발히 활동한다.\n",
            "비 렘수면은 몸은 움직일 수 있지만 뇌는 활동하지 않는 상태다.\n",
            "렘수면 장애는 꿈꾸는 내용대로 행동하는 것이다.\n",
            "옆에서 자는 사람을 때리거나 발로 찰 수 있으며 침대에서 떨어져 다칠 수도 있다.\n",
            "렘수면 장애의 70%는 파킨슨병으로 이어질 수 있다.\n",
            "이 연구 결과는 영국의 의학 전문지 랜싯의 자매지 ‘e임상의학’ 최신호에 게재됐다. [SEP]\n",
            "[CLS] 13세 친딸 몸쓸짓하고 “친구 소개해줘… 40대父 징역 12년 [SEP] 13세 친딸을 수차례 성폭행하고 학대한 혐의로 재판에 넘겨진 40대 남성에게 법원이 징역 12년형을 선고했다.\n",
            "8일 법조계에 따르면 대구지방법원 포항지원 제1형사부는 성폭력 범죄의 처벌 등에 관한 특례법 위반 등으로 기소된 A씨에게 징역 12년을 선고했다고 밝혔다.\n",
            "또, 아동·청소년시설과 장애인복지시설 취업제한 7년과 함께 같은 기간 동안 위치추적 전자장치 부착도 명령했다.\n",
            "A씨는 지난 2018년부터 2020년까지 자신의 딸인 B양을 수차례 강간하고 평소 대답을 잘 하지 않는다는 이유로 학대한 혐의를 받고 있다.\n",
            "A씨가 경제적 지위를 내세워 범행 당시 13세에 불과했던 B양을 협박해 성적 대상자로 삼은 것으로 알려졌다.\n",
            "A씨는 B양이 어머니와 여동생과 함께 자고 있는 상황에서도 성폭력을 행사했다.\n",
            "심지어 A씨는 B양에게 “친구를 소개해 달라”고 요구한 것으로 조사됐다.\n",
            "재판부는 “범행이 장기간에 걸쳐 반복적으로 이뤄지면서 어린 피해자가 오랜 기간 극심한 정신적, 심리적 고통과 성적 수치심에 시달린 것으로 보인다”며 “죄질이 매우 무거워 엄벌이 불가피하나, 피고인이 공소 사실을 모두 인정하고 자신의 잘못을 뉘우친 모습을 보이는 점 등을 참작했다”고 양형 이유를 밝혔다. [SEP]\n",
            "[CLS] 경과원, 인공지능?가상현실 기술 성과공유회 개최 [SEP] 경기도경제과학진흥원은 16일부터 이틀간 경기창조경제혁신센터 국제회의장에서‘2021 성과공유회 가상현실과 인공지능의 만남’ 행사를 개최한다고 15일 밝혔다.\n",
            "이번 행사는 경기도의 VR·AR, AI 실증과제에 대한 지원성과를 공유하고 기술교류를 통한 협업 비즈니스 모델 창출기회 제공하기 위해 마련됐다.\n",
            "코로나19 방역수칙을 준수하여 온·오프라인으로 동시 개최한다. 1일 차인 16일에는 개회식을 시작으로 VR·AR, AI 기술 실증기업의 우수과제 성과공유와 Pitching, 소프트웨어정책연구소 이승환 팀장의 ‘메타버스 비긴즈’ 특별강연으로 진행된다.\n",
            "또 이날 오전 11시부터 개방되는 전시장에는 ‘가상현실과 인공지능의 만남’이라는 주제에 맞춰 경기도에서 지원한 13개 VR·AR 기업과 과기정통부가 지원하고 정보통신산업진흥원을 전담기관으로 지원하는 7개 AI 기업이 전시 및 체험부스를 운영한다. 2일 차인 17일에는 정용찬 정보통신정책연구원 본부장이 ‘메타버스 시대 데이터 거버넌스’ 란 주제로 강연한다.\n",
            "또 민옥기 한국전자통신연구원 본부장이 ‘인공지능 기술현황과 전망’에 대해 특별강연한다.\n",
            "유승경 경과원 원장은 “이번 성과공유회를 통해 경기 도내 VR·AR과 인공지능의 기술적 성과를 직접 체험하고, 이를 통해 관련 산업에 대한 이해도를 높이는 계기가 될 것으로 기대된다”고 말했다. [SEP]\n"
          ]
        }
      ],
      "source": [
        "# 각 헤드라인과 본문을 하나로 붙여서 sentences 만들기\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for i in range(len(sentences_h)):\n",
        "    sentence = sentences_h[i] + \" \" + sentences_c[i]\n",
        "    sentences.append(sentence)\n",
        "\n",
        "# 결과 출력\n",
        "for sentence in sentences[:5]:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe9a0a8c",
      "metadata": {
        "id": "fe9a0a8c",
        "outputId": "c747aa2a-16c1-4f85-eb0d-3a5aee9ce8c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Class(라벨) 추출 : 가짜뉴스 0 / 진짜뉴스 1\n",
        "labels = df['Class'].values\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b153050c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "98a171f7ac9e44bb87d764da1a407287",
            "6af84d9791094cc48a2c31670670f98a",
            "095d6d1795de4bc0a4819e524a3ea2b1",
            "50c38badf9fb47759103bcbd0c937cc1"
          ]
        },
        "id": "b153050c",
        "outputId": "5ed8dfc1-777a-4443-cc60-81efc1a0e763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 광주지역 소상공인의 외침... 코로나 직격탄 맞은 소상공인 도울 방법은? [SEP] 신종 코로나바이러스 감염증 직격탄을 맞은 소상공인들이 저마다 절박한 심정으로 지원을 호소했다.\n",
            "광주시는 10일 시청 중회의실에서 지역 소상공업종 대표들과 간담회를 하고 건의 사항을 청취했다.\n",
            "이날 간담회에는 상인연합회를 비롯해 학원, 노래연습장, 예식업, 단란주점, 제과점, 휴게음식점, 목욕탕, 숙박, 세탁, 이미용업 등 업종 대표 14명이 참석했다.\n",
            "소상공인들은 매출 감소와 각종 제한에 따른 어려움을 토로하고 지원을 요청했다.\n",
            "예식업 대표는 매출 규모를 기준으로 하다 보니 재난 지원금과 시 지원 대상에서 제외됐다고 고충을 털어놨다.\n",
            "목욕업 대표는 손님이 없어도 물을 데워야 하는 특성상 공공요금 부담이 크다 면서 기본요금 감면 등 실질적인 지원이 필요하다고 호소했다.\n",
            "70세 이상 기초생활보장 수급자, 차상위 계층 노인을 위한 경로 목욕비 바우처 사업도 제안됐다.\n",
            "세탁업 대표는 사업자 등록을 하지 않은 업소들은 영업 신고증이 있어도 정부 지원에서 누락되는 경우가 많다며 지원을 호소했다.\n",
            "숙박업 대표는 연 매출 4억원 이상 사업자를 지원에서 제외하는 문제점을 지적하고 착한 임대료 운동을 확산시켜달라고 건의했다.\n",
            "이용섭 광주시장은 미디어SR에 코로나19라는 사회 재난으로 큰 어려움을 겪는 소상공인들의 심정을 충분히 이해한다 며 소상공인이 행복해야 광주가 행복하다는 마음으로 간담회에서 나온 의견을 정책에 반영해 지원 대책을 강구하겠다고 밝혔다. [SEP]\n",
            "['[CLS]', '광', '##주', '##지', '##역', '소', '##상', '##공', '##인의', '외', '##침', '.', '.', '.', '코', '##로', '##나', '직', '##격', '##탄', '맞', '##은', '소', '##상', '##공', '##인', '도', '##울', '방', '##법', '##은', '?', '[SEP]', '신', '##종', '코', '##로', '##나', '##바', '##이', '##러', '##스', '감', '##염', '##증', '직', '##격', '##탄', '##을', '맞', '##은', '소', '##상', '##공', '##인', '##들이', '저', '##마다', '절', '##박', '##한', '심', '##정', '##으로', '지', '##원을', '호', '##소', '##했다', '.', '광', '##주시', '##는', '10일', '시', '##청', '중', '##회의', '##실', '##에서', '지역', '소', '##상', '##공', '##업', '##종', '대', '##표', '##들과', '간', '##담', '##회를', '하고', '건', '##의', '사', '##항', '##을', '청', '##취', '##했다', '.', '이', '##날', '간', '##담', '##회', '##에는', '상', '##인', '##연', '##합', '##회를', '비', '##롯', '##해', '학', '##원', ',', '노래', '##연', '##습', '##장', ',', '예', '##식', '##업', ',', '단', '##란', '##주', '##점', ',', '제', '##과', '##점', ',', '휴', '##게', '##음', '##식', '##점', ',', '목', '##욕', '##탕', ',', '숙', '##박', ',', '세', '##탁', ',', '이미', '##용', '##업', '등', '업', '##종', '대', '##표', '14', '##명이', '참', '##석', '##했다', '.', '소', '##상', '##공', '##인', '##들은', '매', '##출', '감', '##소', '##와', '각', '##종', '제', '##한', '##에', '따른', '어', '##려', '##움을', '토', '##로', '##하고', '지', '##원을', '요', '##청', '##했다', '.', '예', '##식', '##업', '대', '##표', '##는', '매', '##출', '규', '##모', '##를', '기준으로', '하다', '보', '##니', '재', '##난', '지', '##원', '##금', '##과', '시', '지', '##원', '대', '##상', '##에서', '제', '##외', '##됐', '##다고', '고', '##충', '##을', '[UNK]', '.', '목', '##욕', '##업', '대', '##표', '##는', '손', '##님', '##이', '없', '##어', '##도', '물', '##을', '데', '##워', '##야', '하는', '특', '##성', '##상', '공', '##공', '##요', '##금', '부', '##담', '##이', '크', '##다', '면', '##서', '기', '##본', '##요', '##금', '감', '##면', '등', '실', '##질', '##적인', '지', '##원이', '필', '##요', '##하다', '##고', '호', '##소', '##했다', '.', '70', '##세', '이상', '기', '##초', '##생', '##활', '##보', '##장', '수', '##급', '##자', ',', '차', '##상', '##위', '계', '##층', '노', '##인을', '위한', '경', '##로', '목', '##욕', '##비', '바', '##우', '##처', '사', '##업', '##도', '제', '##안', '##됐', '##다', '.', '세', '##탁', '##업', '대', '##표', '##는', '사', '##업', '##자', '등', '##록', '##을', '하지', '않은', '업', '##소', '##들은', '영', '##업', '신', '##고', '##증', '##이', '있어', '##도', '정', '##부', '지', '##원에', '##서', '누', '##락', '##되는', '경우가', '많다', '##며', '지', '##원을', '호', '##소', '##했다', '.', '숙', '##박', '##업', '대', '##표', '##는', '연', '매', '##출', '4', '##억', '##원', '이상', '사', '##업', '##자를', '지', '##원에', '##서', '제', '##외', '##하는', '문', '##제', '##점을', '지', '##적', '##하고', '착', '##한', '임', '##대', '##료', '운', '##동을', '확', '##산', '##시', '##켜', '##달', '##라고', '건', '##의', '##했다', '.', '이', '##용', '##섭', '광', '##주시', '##장은', '미', '##디', '##어', '##SR', '##에', '코', '##로', '##나', '##19', '##라는', '사', '##회', '재', '##난', '##으로', '큰', '어', '##려', '##움을', '겪', '##는', '소', '##상', '##공', '##인', '##들의', '심', '##정을', '충', '##분', '##히', '이', '##해', '##한다', '며', '소', '##상', '##공', '##인이', '행', '##복', '##해야', '광', '##주', '##가', '행', '##복', '##하다', '##는', '마', '##음', '##으로', '간', '##담', '##회', '##에서', '나', '##온', '의', '##견', '##을', '정', '##책', '##에', '반', '##영', '##해', '지', '##원', '대', '##책', '##을', '강', '##구', '##하', '##겠', '##다고', '밝혔다', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f83fad-1743-4beb-a9bb-cd08b61764fe",
      "metadata": {
        "id": "e2f83fad-1743-4beb-a9bb-cd08b61764fe",
        "outputId": "d6bba7fe-cbc9-43eb-92c4-502c1018aa88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37da18b",
      "metadata": {
        "id": "f37da18b",
        "outputId": "bb20a087-c948-4251-a875-cabadbe764c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "token_len = [len(tokenized_texts[i]) for i in range(len(tokenized_texts))]\n",
        "plt.hist(token_len)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cddd7c",
      "metadata": {
        "id": "c5cddd7c",
        "outputId": "67e136fb-7c63-47c2-e3ad-f795fcdea00b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   101,   8903,  16323,  12508,  23160,   9448,  14871,  28000,\n",
              "        48418,   9597, 119285,    119,    119,    119,   9812,  11261,\n",
              "        16439,   9707,  45465,  66554,   9256,  10892,   9448,  14871,\n",
              "        28000,  12030,   9087,  78123,   9328,  33768,  10892,    136,\n",
              "          102,   9487,  22200,   9812,  11261,  16439,  42144,  10739,\n",
              "        30873,  12605,   8848, 119144, 119230,   9707,  45465,  66554,\n",
              "        10622,   9256,  10892,   9448,  14871,  28000,  12030,  20173,\n",
              "         9663, 101814,   9666, 118963,  11102,   9491,  16605,  11467,\n",
              "         9706,  51684,   9985,  22333,  12490,    119,   8903,  87281,\n",
              "        11018,  39335,   9485,  40311,   9694,  56356,  31503,  11489,\n",
              "        58939,   9448,  14871,  28000,  26784,  22200,   9069,  37824,\n",
              "        72482,   8845, 105462,  88168,  32487,   8865,  10459,   9405,\n",
              "        50632,  10622,   9751, 119279,  12490,    119,   9638,  41919,\n",
              "         8845, 105462,  14863,  15303,   9414,  12030,  25486,  33188,\n",
              "        88168,   9379, 118885,  14523,   9953,  14279,    117,  99706,\n",
              "        25486, 119081,  13890,    117,   9576,  21155,  26784,    117,\n",
              "         9059,  49919,  16323,  34907,    117,   9672,  11882,  34907,\n",
              "          117,  10013,  14153,  32158,  21155,  34907,    117,   9284,\n",
              "       109971, 119341,    117,   9461, 118963,    117,   9435, 119335,\n",
              "          117,  71771,  24974,  26784,   9121,   9554,  22200,   9069,\n",
              "        37824,  10247,  66923,   9735,  40958,  12490,    119,   9448,\n",
              "        14871,  28000,  12030,  22879,   9258,  52363,   8848,  22333,\n",
              "        12638,   8844,  22200,   9672,  11102,  10530, 110463,   9546,\n",
              "        26737,  90373,   9873,  11261,  12453,   9706,  51684,   9599,\n",
              "        40311,  12490,    119,   9576,  21155,  26784,   9069,  37824,\n",
              "        11018,   9258,  52363,   8922,  39420,  11513,  81600,  80564,\n",
              "         9356,  25503,   9659,  33305,   9706,  14279,  40032,  11882,\n",
              "         9485,   9706,  14279,   9069,  14871,  11489,   9672,  78705,\n",
              "       118799,  85634,   8888, 119276,  10622,    100,    119,   9284,\n",
              "       109971,  26784,   9069,  37824,  11018,   9450, 108578,  10739,\n",
              "         9555,  12965,  12092,   9299,  10622,   9083,  69592,  21711,\n",
              "        23969,   9891,  17138,  14871,   8896,  28000,  48549,  40032,\n",
              "         9365, 105462,  10739,   9834,  11903,   9279,  12424,   8932,\n",
              "        40419,  48549,  40032,   8848,  14867,   9121,   9489,  48599,\n",
              "        15387,   9706,  73295,   9949,  48549,  32679,  11664,   9985,\n",
              "        22333,  12490,    119,  10923,  24982,  66982,   8932,  57030,\n",
              "        24017, 119446,  30005,  13890,   9460,  37568,  13764,    117,\n",
              "         9730,  14871,  19855,   8887,  70450,   9022,  83200,  28195,\n",
              "         8885,  11261,   9284, 109971,  29455,   9318,  27355,  60469,\n",
              "         9405,  26784,  12092,   9672,  34951, 118799,  11903,    119,\n",
              "         9435, 119335,  26784,   9069,  37824,  11018,   9405,  26784,\n",
              "        13764,   9121,  31398,  10622,  89093,  54543,   9554,  22333,\n",
              "        22879,   9574,  26784,   9487,  11664, 119230,  10739,  45893,\n",
              "        12092,   9670,  14646,   9706, 108280,  12424,   9032, 107693,\n",
              "        24683, 108462, 100313,  21406,   9706,  51684,   9985,  22333,\n",
              "        12490,    119,   9461, 118963,  26784,   9069,  37824,  11018,\n",
              "         9568,   9258,  52363,    125,  91837,  14279,  66982,   9405,\n",
              "        26784,  48959,   9706, 108280,  12424,   9672,  78705,  12178,\n",
              "         9297,  17730,  67477,   9706,  14801,  12453,   9731,  11102,\n",
              "         9644,  14423,  38688,   9606,  69448,   9994,  21386,  14040,\n",
              "       100110,  89851,  59894,   8865,  10459,  12490,    119,   9638,\n",
              "        24974, 119041,   8903,  87281,  63671,   9309,  48446,  12965,\n",
              "        52238,  10530,   9812,  11261,  16439,  54055,  60362,   9405,\n",
              "        14863,   9659,  33305,  11467,   9835,   9546,  26737,  90373,\n",
              "         8879,  11018,   9448,  14871,  28000,  12030,  25258,   9491,\n",
              "        40818,   9770,  37712,  18108,   9638,  14523,  14102,   9278,\n",
              "         9448,  14871])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 450\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e14b42",
      "metadata": {
        "id": "f2e14b42",
        "outputId": "a4952464-b13e-428e-9d4a-a32c66070eee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "## 어텐션 마스크\n",
        "\n",
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc46965",
      "metadata": {
        "id": "fcc46965",
        "outputId": "6462241f-5b76-44ce-93eb-494404509008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([   101,   9672, 118925,  37601,   9379,  37568,  29935,   9708,  38688,\n",
            "         29455,    117,   9379,  25242,  22440,   9471,  14153,   9659,  16605,\n",
            "         29455,    102,   9637,  38688,  12310,  20595, 101814,   9672, 118925,\n",
            "         37601, 103064,   9379,  37568,  29935,  18623,  38688,  29455,   9670,\n",
            "         30005,  11287,   9659,  16605,  29455,  22096,    119,   9356,  71439,\n",
            "         70915,  12508,  58904,   9637,  38688,  12310,  20595,  10459,   9379,\n",
            "         37568,  29935,   9379,  24974,   8888,  12508,   9328,  94199,   8908,\n",
            "         29683,  17022,   9672,  14040,  48533,  11467,  73131,   8909,  36553,\n",
            "         20173,   9637,  38688,  12310,  20595,   9638,  24974,  14040,   9379,\n",
            "         37568,  29935,   9379,  72444, 106154,   9524,  12310,   9471,  11664,\n",
            "           117,   9737,  12310,   9471,  71689,   9379,  37568,  29935,   9708,\n",
            "         38688,  29455,  24974,   8888,  12508,   9706, 119285,  10622,   8857,\n",
            "         59456,  85634,  99896,    119,   8924,  93867,   8909,  36553,  10459,\n",
            "          9524,   8917,  12692,   9356,  35963,  19905,   9379,  37568,  29935,\n",
            "          8843,  53635,   8932,  36210,  11102,   9739,  13764,  33727,   9637,\n",
            "         38688,  12310,  20595,  10530,   9379,  18622,  12453,   9640,  21876,\n",
            "         82881,   9989, 119391,  44359,  10530,   8872,  14040,  35506,  71689,\n",
            "         23622,    119,  21890,   9637,  38688,  12310,  20595,  10739,   9651,\n",
            "        119183,  15387,   9328,  72687,   8888,  12508,  32679,   9356,  25503,\n",
            "          8932,  20595, 101814,   9603,  12965,  12638,   9367,  46520,   9328,\n",
            "         21155,  10739,   9061, 106220,    119,  86838,  25934,  10530,   8909,\n",
            "         36553,  20173,   9638,  14523,  12453,   8843,  45465,   9379,  25242,\n",
            "         22440,  10530,   9546,  26737, 119169,  10739,  24335,    119,   9144,\n",
            "          8932,  20595,   8996,   9379,  18622,   9657,  22333,  16439,   9989,\n",
            "        119391,  44359,   8996,   9619,  62672,   9737,  12310,   9546, 118879,\n",
            "         82034,   9706,  14801,  10739,  45893,   9594,  11903,    119,  41099,\n",
            "          9379,  37568,  29935,   9959,  68055,   9603,  12965,  12638,   9367,\n",
            "         46520,  29683,  54163,   9130,  31401,  71689,   9934,  54867,  18227,\n",
            "         12453,   8908,  29683,  15387,   9543,  48132,   9672,  28000,  48533,\n",
            "         11467,  73131,   9637,  38688,  12310,  20595,  10739,   9471,  14153,\n",
            "          8888,  12508,  14843,   9460,  40523,   8909,  36553,  27023,  12092,\n",
            "          9471,  14153,   9737,  10622,   9460, 107931,  23622,    119,   8857,\n",
            "         16605,  34951,  10530,  59355,  96567,   9379,  37568,  29935,   9379,\n",
            "         72444,   9966,  19855,  38688,    117,   9779,  38688,  36210,  38688,\n",
            "         14423,    117,   9539,  17730,  29455,    117,   9672, 119230,  16758,\n",
            "         15891,  15891,  38688,    117,   9428, 119342,  18623,  38688,  38688,\n",
            "         10459,    126,  37712,  21711,  11261,   9367,  46520,  12490,    119,\n",
            "          9485,  51945,  38688,    117,   8868,  12945,  38688,   9121,   9966,\n",
            "         19855,  38688,  11018,   9779,  38688,  36210,  38688,  12638,   9539,\n",
            "         54480,   9928,  48533,  24683, 108462,   9249,  16985,   9779,  38688,\n",
            "         36210,  38688,  12638,   9539,  17730,  29455,   9928,  48533,   9565,\n",
            "         73969,   8932,  36210,  35506,  71689,  32487,    117,  99448,   9489,\n",
            "         14040,   9761,  29455,  24974,  11467,   8932,  36210,  26444,  31398,\n",
            "          8917,  13890,  13374,  96567,   9379,  24974,   9901, 119110,  10739,\n",
            "          9603,  10739,  35506,  71689,  23622,    119,   9637,  38688,  12310,\n",
            "         20595,   8996,  10459,   9379,  18622,   9657,  22333,  11018,   9521,\n",
            "         31605,  28911,  12605,  20308,  16439,   9669,  15891, 100420,  17196,\n",
            "         11261, 104153,  14523,   9521,  31605,  33323,  10622, 102221,  17594,\n",
            "         32487,    117,   9989, 119391,  44359,   9750,  18227,  14867,  10530,\n",
            "          9330,  18622,  12453,   8868,  41442,   8932, 100819,   9672,  28000])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor([   101,   9069, 118782,  21386,  24989,   9994,  18623,  13764,   9323,\n",
            "         24017,  10530,   9645,  16323,  12310,  26784,   8933,  13890, 105197,\n",
            "          8888,  20626,    102,   9706,  33305,  45367,   9069, 118782,  21386,\n",
            "         26784,  24989,  12508,   8996,   9645,  16323,   8932,  26784,  11489,\n",
            "          9812,  11261,  16439,  54055,   9994,  18623,  38939,   9323,  24017,\n",
            "         37341,   9407,  26784,  24989,  12508,   8932,  26784,  25258,   8933,\n",
            "         13890, 105197,  10739,   8888,  20626,  29208,  11506,    119,   9994,\n",
            "         18623,  38939,   9420,  12310,  14867,   9405,  26784,  13890,   9927,\n",
            "        119058,   9678, 104504,   8996,  26737,  12508,  12310,  70336,    119,\n",
            "          8932,  26784,  22879,   9450,   9448,  80331,  17730,   9379,  18622,\n",
            "           117,   9246,  12605,  20308,   9731,  24974,  33727,   9420, 119446,\n",
            "         18227,  22766,   9812,  11261,  16439,  54055,   9069, 119187,  10530,\n",
            "          9761,  33975,   8932,  78123,  54355,  76123,    117,   9407,  26784,\n",
            "         24989,  84899,  37321,  70258,   9994,  18623,  38939,   9323,  24017,\n",
            "         11102,   9248, 119328,    117,   9576,  42337,  20626,  62672,   9069,\n",
            "        119400,   8853,  18227,  12453,  11506,    119,  43494, 103988,  14040,\n",
            "         12638,   9069, 118782,  21386,  26784,  24989,  12508,  20595,  12692,\n",
            "         28000,  24989,  77547,  59355,   9665,  41919, 103988,  11489,   9812,\n",
            "         11261,  16439,  54055,  10208,  48506,   9994,  18623,  38939,   9323,\n",
            "         24017,  12490,    119,  58939,   9750,   9487,  38631,  12508,   8907,\n",
            "         12030,   9994,  18623,  57713,    117,   9625,  17138,  17196,   9657,\n",
            "         14423,  18778,  10530,   8863,  16323,  12178,  10197,  14423,   8987,\n",
            "         53371,  11903,    119,   9707,  63671,   9069, 118782,  17196,   9297,\n",
            "        119398,  18778,  10530,  13767,   9069, 118782,  21386,  26784,  24989,\n",
            "         12508,   9645,  16323,   8932,  26784,  11925,    119,   9638,  11261,\n",
            "         39629,   9069, 118782,  21386,  26784,  24989,  12508,   8932,  26784,\n",
            "         27023,  12092,   9379,  83902,   8867,  45554,    119,   8932,  26784,\n",
            "         25258,  28467,   8924,  93867,   9998,  12945,   9707,  73295,  16439,\n",
            "          8843,  52560,  10739,   9812,  11261,  16439,  54055,   9994,  18623,\n",
            "         57713,   9903,  16605, 118800,  14867,   9405,  26784,  35963,   9927,\n",
            "        119058,  12490,    119,   9706,  33305,  89851,  49780,  16617,  53639,\n",
            "          9640,  38631,  12945,  26784,  13890,   9707,  74125,   8843,  52560,\n",
            "         10739,   9994,  18623,  57713,   9903,  16605, 118801,  10530,  22799,\n",
            "         91621,   9707,  73295,   8926,  32537,  76424,  91785,  69448,   9952,\n",
            "         35866,   9927, 119058,  12490,    119,  18589,   9061,   9410,  17138,\n",
            "         16617,  13764,  23635,   8908,  22458,  12945,  26784,  13890,   9707,\n",
            "         73295,   9812,  11261,  16439,  54055,   9994,  18623,   9903,  40818,\n",
            "         70930,   9665,   9405,  26784,  55635,   9641,  14040,   9927, 119058,\n",
            "        118799,  11903,    119,   9410,  17138,  16617,  53639,   9994,  18623,\n",
            "         89389,   9669, 119267,  11102,   9095,  38688,  25820,   9651,  11287,\n",
            "         45465,  12692,   9678,  18622,  12453,    117,   9405,  26784,  13890,\n",
            "          9665,   9707,  51684,   9678,  12310,   8920,  11287,  14040, 100110,\n",
            "          9405,  26784,  35963,   9379,  21614,   9109,   9670, 118958,   9328,\n",
            "         23160,  10622,   9489,  14040,  12490,    119,  21275,  35506,  10739,\n",
            "        118766,  63591,   9069,  17196,   9994,  18623,  89389,   9669, 119267,\n",
            "         11102,   9487,  58303,  12945,  14279,  11882,   9927, 118878,   9705,\n",
            "         33654,   9356,  12030,   9707,  73295,   8982,  12638,   9638,  38631,\n",
            "        119294,  68984,  12605,   9644,  33077,  14279,  11900,  29935,  52859,\n",
            "          9651,  11287,  45465,  12692,   9678,  18622,  12490,    119,   9407,\n",
            "         26784,  24989,  12508,   8932,  26784,  22879,   9812,  11261,  16439])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "df_inputs, validation_inputs, df_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels,\n",
        "                                                                                    random_state=2018,\n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "df_masks, validation_masks, _, _ = train_test_split(attention_masks,\n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018,\n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "df_inputs = torch.tensor(df_inputs)\n",
        "df_labels = torch.tensor(df_labels)\n",
        "df_masks = torch.tensor(df_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "print(df_inputs[0])\n",
        "print(df_labels[0])\n",
        "print(df_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc33d552",
      "metadata": {
        "id": "cc33d552"
      },
      "outputs": [],
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 8\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "df_data = TensorDataset(df_inputs, df_masks, df_labels)\n",
        "df_sampler = RandomSampler(df_data)\n",
        "df_dataloader = DataLoader(df_data, sampler=df_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 생성"
      ],
      "metadata": {
        "id": "Q04CtmZIykU0"
      },
      "id": "Q04CtmZIykU0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ad521d",
      "metadata": {
        "id": "72ad521d",
        "outputId": "bf0c1699-b4be-4665-e468-2a33a930da5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:41:15.936372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-04 14:41:15.938972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-04 14:41:15.939076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-04 14:41:16.978901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-04 14:41:16.978993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-04 14:41:16.979041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-04 14:41:16.979086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 21097 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "## 모델 생성\n",
        "\n",
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f0b0f0",
      "metadata": {
        "id": "87f0b0f0",
        "outputId": "7a185124-bd34-48a5-a43f-1f6e7abe475e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA GeForce RTX 4090\n"
          ]
        }
      ],
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc5f027",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "fe7cd32897d7471ab9ecf9080ec72aac"
          ]
        },
        "id": "ddc5f027",
        "outputId": "7ee47447-6317-46d4-a830-a6a698bfe59f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfab44e",
      "metadata": {
        "id": "bcfab44e",
        "outputId": "30616cda-e828-4121-c8a8-4410645a6a98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hyunkoo/anaconda3/envs/uhyeon/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(df_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ec1344",
      "metadata": {
        "id": "a1ec1344"
      },
      "outputs": [],
      "source": [
        "## 모델학습\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a15423",
      "metadata": {
        "id": "04a15423"
      },
      "outputs": [],
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습"
      ],
      "metadata": {
        "id": "ilB9jtd2ypGi"
      },
      "id": "ilB9jtd2ypGi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ab332e",
      "metadata": {
        "id": "72ab332e",
        "outputId": "7516a267-885e-4399-ed01-ccb5159a202c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  35,790.    Elapsed: 0:00:50.\n",
            "  Batch 1,000  of  35,790.    Elapsed: 0:01:41.\n",
            "  Batch 1,500  of  35,790.    Elapsed: 0:02:32.\n",
            "  Batch 2,000  of  35,790.    Elapsed: 0:03:22.\n",
            "  Batch 2,500  of  35,790.    Elapsed: 0:04:12.\n",
            "  Batch 3,000  of  35,790.    Elapsed: 0:05:02.\n",
            "  Batch 3,500  of  35,790.    Elapsed: 0:05:52.\n",
            "  Batch 4,000  of  35,790.    Elapsed: 0:06:42.\n",
            "  Batch 4,500  of  35,790.    Elapsed: 0:07:31.\n",
            "  Batch 5,000  of  35,790.    Elapsed: 0:08:21.\n",
            "  Batch 5,500  of  35,790.    Elapsed: 0:09:11.\n",
            "  Batch 6,000  of  35,790.    Elapsed: 0:10:01.\n",
            "  Batch 6,500  of  35,790.    Elapsed: 0:10:51.\n",
            "  Batch 7,000  of  35,790.    Elapsed: 0:11:41.\n",
            "  Batch 7,500  of  35,790.    Elapsed: 0:12:30.\n",
            "  Batch 8,000  of  35,790.    Elapsed: 0:13:20.\n",
            "  Batch 8,500  of  35,790.    Elapsed: 0:14:10.\n",
            "  Batch 9,000  of  35,790.    Elapsed: 0:15:00.\n",
            "  Batch 9,500  of  35,790.    Elapsed: 0:15:50.\n",
            "  Batch 10,000  of  35,790.    Elapsed: 0:16:40.\n",
            "  Batch 10,500  of  35,790.    Elapsed: 0:17:29.\n",
            "  Batch 11,000  of  35,790.    Elapsed: 0:18:19.\n",
            "  Batch 11,500  of  35,790.    Elapsed: 0:19:09.\n",
            "  Batch 12,000  of  35,790.    Elapsed: 0:19:59.\n",
            "  Batch 12,500  of  35,790.    Elapsed: 0:20:49.\n",
            "  Batch 13,000  of  35,790.    Elapsed: 0:21:39.\n",
            "  Batch 13,500  of  35,790.    Elapsed: 0:22:28.\n",
            "  Batch 14,000  of  35,790.    Elapsed: 0:23:18.\n",
            "  Batch 14,500  of  35,790.    Elapsed: 0:24:08.\n",
            "  Batch 15,000  of  35,790.    Elapsed: 0:24:58.\n",
            "  Batch 15,500  of  35,790.    Elapsed: 0:25:48.\n",
            "  Batch 16,000  of  35,790.    Elapsed: 0:26:38.\n",
            "  Batch 16,500  of  35,790.    Elapsed: 0:27:27.\n",
            "  Batch 17,000  of  35,790.    Elapsed: 0:28:17.\n",
            "  Batch 17,500  of  35,790.    Elapsed: 0:29:07.\n",
            "  Batch 18,000  of  35,790.    Elapsed: 0:29:57.\n",
            "  Batch 18,500  of  35,790.    Elapsed: 0:30:47.\n",
            "  Batch 19,000  of  35,790.    Elapsed: 0:31:37.\n",
            "  Batch 19,500  of  35,790.    Elapsed: 0:32:27.\n",
            "  Batch 20,000  of  35,790.    Elapsed: 0:33:16.\n",
            "  Batch 20,500  of  35,790.    Elapsed: 0:34:06.\n",
            "  Batch 21,000  of  35,790.    Elapsed: 0:34:56.\n",
            "  Batch 21,500  of  35,790.    Elapsed: 0:35:46.\n",
            "  Batch 22,000  of  35,790.    Elapsed: 0:36:36.\n",
            "  Batch 22,500  of  35,790.    Elapsed: 0:37:25.\n",
            "  Batch 23,000  of  35,790.    Elapsed: 0:38:15.\n",
            "  Batch 23,500  of  35,790.    Elapsed: 0:39:05.\n",
            "  Batch 24,000  of  35,790.    Elapsed: 0:39:55.\n",
            "  Batch 24,500  of  35,790.    Elapsed: 0:40:45.\n",
            "  Batch 25,000  of  35,790.    Elapsed: 0:41:35.\n",
            "  Batch 25,500  of  35,790.    Elapsed: 0:42:24.\n",
            "  Batch 26,000  of  35,790.    Elapsed: 0:43:14.\n",
            "  Batch 26,500  of  35,790.    Elapsed: 0:44:04.\n",
            "  Batch 27,000  of  35,790.    Elapsed: 0:44:54.\n",
            "  Batch 27,500  of  35,790.    Elapsed: 0:45:44.\n",
            "  Batch 28,000  of  35,790.    Elapsed: 0:46:33.\n",
            "  Batch 28,500  of  35,790.    Elapsed: 0:47:23.\n",
            "  Batch 29,000  of  35,790.    Elapsed: 0:48:13.\n",
            "  Batch 29,500  of  35,790.    Elapsed: 0:49:03.\n",
            "  Batch 30,000  of  35,790.    Elapsed: 0:49:53.\n",
            "  Batch 30,500  of  35,790.    Elapsed: 0:50:43.\n",
            "  Batch 31,000  of  35,790.    Elapsed: 0:51:32.\n",
            "  Batch 31,500  of  35,790.    Elapsed: 0:52:22.\n",
            "  Batch 32,000  of  35,790.    Elapsed: 0:53:12.\n",
            "  Batch 32,500  of  35,790.    Elapsed: 0:54:02.\n",
            "  Batch 33,000  of  35,790.    Elapsed: 0:54:52.\n",
            "  Batch 33,500  of  35,790.    Elapsed: 0:55:41.\n",
            "  Batch 34,000  of  35,790.    Elapsed: 0:56:31.\n",
            "  Batch 34,500  of  35,790.    Elapsed: 0:57:21.\n",
            "  Batch 35,000  of  35,790.    Elapsed: 0:58:11.\n",
            "  Batch 35,500  of  35,790.    Elapsed: 0:59:02.\n",
            "\n",
            "  Average Data loss: 0.51\n",
            "  Training epcoh took: 0:59:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:01:54\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  35,790.    Elapsed: 0:00:52.\n",
            "  Batch 1,000  of  35,790.    Elapsed: 0:01:45.\n",
            "  Batch 1,500  of  35,790.    Elapsed: 0:02:40.\n",
            "  Batch 2,000  of  35,790.    Elapsed: 0:03:34.\n",
            "  Batch 2,500  of  35,790.    Elapsed: 0:04:27.\n",
            "  Batch 3,000  of  35,790.    Elapsed: 0:05:17.\n",
            "  Batch 3,500  of  35,790.    Elapsed: 0:06:09.\n",
            "  Batch 4,000  of  35,790.    Elapsed: 0:07:00.\n",
            "  Batch 4,500  of  35,790.    Elapsed: 0:07:51.\n",
            "  Batch 5,000  of  35,790.    Elapsed: 0:08:42.\n",
            "  Batch 5,500  of  35,790.    Elapsed: 0:09:32.\n",
            "  Batch 6,000  of  35,790.    Elapsed: 0:10:22.\n",
            "  Batch 6,500  of  35,790.    Elapsed: 0:11:12.\n",
            "  Batch 7,000  of  35,790.    Elapsed: 0:12:02.\n",
            "  Batch 7,500  of  35,790.    Elapsed: 0:12:52.\n",
            "  Batch 8,000  of  35,790.    Elapsed: 0:13:41.\n",
            "  Batch 8,500  of  35,790.    Elapsed: 0:14:31.\n",
            "  Batch 9,000  of  35,790.    Elapsed: 0:15:21.\n",
            "  Batch 9,500  of  35,790.    Elapsed: 0:16:11.\n",
            "  Batch 10,000  of  35,790.    Elapsed: 0:17:01.\n",
            "  Batch 10,500  of  35,790.    Elapsed: 0:17:51.\n",
            "  Batch 11,000  of  35,790.    Elapsed: 0:18:41.\n",
            "  Batch 11,500  of  35,790.    Elapsed: 0:19:30.\n",
            "  Batch 12,000  of  35,790.    Elapsed: 0:20:20.\n",
            "  Batch 12,500  of  35,790.    Elapsed: 0:21:10.\n",
            "  Batch 13,000  of  35,790.    Elapsed: 0:22:00.\n",
            "  Batch 13,500  of  35,790.    Elapsed: 0:22:50.\n",
            "  Batch 14,000  of  35,790.    Elapsed: 0:23:40.\n",
            "  Batch 14,500  of  35,790.    Elapsed: 0:24:30.\n",
            "  Batch 15,000  of  35,790.    Elapsed: 0:25:19.\n",
            "  Batch 15,500  of  35,790.    Elapsed: 0:26:09.\n",
            "  Batch 16,000  of  35,790.    Elapsed: 0:26:59.\n",
            "  Batch 16,500  of  35,790.    Elapsed: 0:27:49.\n",
            "  Batch 17,000  of  35,790.    Elapsed: 0:28:39.\n",
            "  Batch 17,500  of  35,790.    Elapsed: 0:29:29.\n",
            "  Batch 18,000  of  35,790.    Elapsed: 0:30:19.\n",
            "  Batch 18,500  of  35,790.    Elapsed: 0:31:08.\n",
            "  Batch 19,000  of  35,790.    Elapsed: 0:31:58.\n",
            "  Batch 19,500  of  35,790.    Elapsed: 0:32:48.\n",
            "  Batch 20,000  of  35,790.    Elapsed: 0:33:38.\n",
            "  Batch 20,500  of  35,790.    Elapsed: 0:34:28.\n",
            "  Batch 21,000  of  35,790.    Elapsed: 0:35:18.\n",
            "  Batch 21,500  of  35,790.    Elapsed: 0:36:08.\n",
            "  Batch 22,000  of  35,790.    Elapsed: 0:36:57.\n",
            "  Batch 22,500  of  35,790.    Elapsed: 0:37:47.\n",
            "  Batch 23,000  of  35,790.    Elapsed: 0:38:37.\n",
            "  Batch 23,500  of  35,790.    Elapsed: 0:39:27.\n",
            "  Batch 24,000  of  35,790.    Elapsed: 0:40:17.\n",
            "  Batch 24,500  of  35,790.    Elapsed: 0:41:07.\n",
            "  Batch 25,000  of  35,790.    Elapsed: 0:41:56.\n",
            "  Batch 25,500  of  35,790.    Elapsed: 0:42:46.\n",
            "  Batch 26,000  of  35,790.    Elapsed: 0:43:36.\n",
            "  Batch 26,500  of  35,790.    Elapsed: 0:44:26.\n",
            "  Batch 27,000  of  35,790.    Elapsed: 0:45:16.\n",
            "  Batch 27,500  of  35,790.    Elapsed: 0:46:06.\n",
            "  Batch 28,000  of  35,790.    Elapsed: 0:46:55.\n",
            "  Batch 28,500  of  35,790.    Elapsed: 0:47:45.\n",
            "  Batch 29,000  of  35,790.    Elapsed: 0:48:35.\n",
            "  Batch 29,500  of  35,790.    Elapsed: 0:49:25.\n",
            "  Batch 30,000  of  35,790.    Elapsed: 0:50:16.\n",
            "  Batch 30,500  of  35,790.    Elapsed: 0:51:06.\n",
            "  Batch 31,000  of  35,790.    Elapsed: 0:51:56.\n",
            "  Batch 31,500  of  35,790.    Elapsed: 0:52:46.\n",
            "  Batch 32,000  of  35,790.    Elapsed: 0:53:36.\n",
            "  Batch 32,500  of  35,790.    Elapsed: 0:54:26.\n",
            "  Batch 33,000  of  35,790.    Elapsed: 0:55:16.\n",
            "  Batch 33,500  of  35,790.    Elapsed: 0:56:06.\n",
            "  Batch 34,000  of  35,790.    Elapsed: 0:56:55.\n",
            "  Batch 34,500  of  35,790.    Elapsed: 0:57:45.\n",
            "  Batch 35,000  of  35,790.    Elapsed: 0:58:35.\n",
            "  Batch 35,500  of  35,790.    Elapsed: 0:59:25.\n",
            "\n",
            "  Average Data loss: 0.43\n",
            "  Training epcoh took: 0:59:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:01:53\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  35,790.    Elapsed: 0:00:50.\n",
            "  Batch 1,000  of  35,790.    Elapsed: 0:01:40.\n",
            "  Batch 1,500  of  35,790.    Elapsed: 0:02:30.\n",
            "  Batch 2,000  of  35,790.    Elapsed: 0:03:19.\n",
            "  Batch 2,500  of  35,790.    Elapsed: 0:04:09.\n",
            "  Batch 3,000  of  35,790.    Elapsed: 0:04:59.\n",
            "  Batch 3,500  of  35,790.    Elapsed: 0:05:49.\n",
            "  Batch 4,000  of  35,790.    Elapsed: 0:06:39.\n",
            "  Batch 4,500  of  35,790.    Elapsed: 0:07:29.\n",
            "  Batch 5,000  of  35,790.    Elapsed: 0:08:19.\n",
            "  Batch 5,500  of  35,790.    Elapsed: 0:09:08.\n",
            "  Batch 6,000  of  35,790.    Elapsed: 0:09:58.\n",
            "  Batch 6,500  of  35,790.    Elapsed: 0:10:48.\n",
            "  Batch 7,000  of  35,790.    Elapsed: 0:11:38.\n",
            "  Batch 7,500  of  35,790.    Elapsed: 0:12:28.\n",
            "  Batch 8,000  of  35,790.    Elapsed: 0:13:18.\n",
            "  Batch 8,500  of  35,790.    Elapsed: 0:14:07.\n",
            "  Batch 9,000  of  35,790.    Elapsed: 0:14:57.\n",
            "  Batch 9,500  of  35,790.    Elapsed: 0:15:47.\n",
            "  Batch 10,000  of  35,790.    Elapsed: 0:16:37.\n",
            "  Batch 10,500  of  35,790.    Elapsed: 0:17:27.\n",
            "  Batch 11,000  of  35,790.    Elapsed: 0:18:17.\n",
            "  Batch 11,500  of  35,790.    Elapsed: 0:19:08.\n",
            "  Batch 12,000  of  35,790.    Elapsed: 0:19:58.\n",
            "  Batch 12,500  of  35,790.    Elapsed: 0:20:48.\n",
            "  Batch 13,000  of  35,790.    Elapsed: 0:21:39.\n",
            "  Batch 13,500  of  35,790.    Elapsed: 0:22:29.\n",
            "  Batch 14,000  of  35,790.    Elapsed: 0:23:19.\n",
            "  Batch 14,500  of  35,790.    Elapsed: 0:24:09.\n",
            "  Batch 15,000  of  35,790.    Elapsed: 0:25:00.\n",
            "  Batch 15,500  of  35,790.    Elapsed: 0:25:50.\n",
            "  Batch 16,000  of  35,790.    Elapsed: 0:26:40.\n",
            "  Batch 16,500  of  35,790.    Elapsed: 0:27:30.\n",
            "  Batch 17,000  of  35,790.    Elapsed: 0:28:21.\n",
            "  Batch 17,500  of  35,790.    Elapsed: 0:29:11.\n",
            "  Batch 18,000  of  35,790.    Elapsed: 0:30:01.\n",
            "  Batch 18,500  of  35,790.    Elapsed: 0:30:51.\n",
            "  Batch 19,000  of  35,790.    Elapsed: 0:31:42.\n",
            "  Batch 19,500  of  35,790.    Elapsed: 0:32:32.\n",
            "  Batch 20,000  of  35,790.    Elapsed: 0:33:22.\n",
            "  Batch 20,500  of  35,790.    Elapsed: 0:34:13.\n",
            "  Batch 21,000  of  35,790.    Elapsed: 0:35:03.\n",
            "  Batch 21,500  of  35,790.    Elapsed: 0:35:53.\n",
            "  Batch 22,000  of  35,790.    Elapsed: 0:36:43.\n",
            "  Batch 22,500  of  35,790.    Elapsed: 0:37:32.\n",
            "  Batch 23,000  of  35,790.    Elapsed: 0:38:22.\n",
            "  Batch 23,500  of  35,790.    Elapsed: 0:39:12.\n",
            "  Batch 24,000  of  35,790.    Elapsed: 0:40:02.\n",
            "  Batch 24,500  of  35,790.    Elapsed: 0:40:52.\n",
            "  Batch 25,000  of  35,790.    Elapsed: 0:41:42.\n",
            "  Batch 25,500  of  35,790.    Elapsed: 0:42:32.\n",
            "  Batch 26,000  of  35,790.    Elapsed: 0:43:22.\n",
            "  Batch 26,500  of  35,790.    Elapsed: 0:44:12.\n",
            "  Batch 27,000  of  35,790.    Elapsed: 0:45:01.\n",
            "  Batch 27,500  of  35,790.    Elapsed: 0:45:51.\n",
            "  Batch 28,000  of  35,790.    Elapsed: 0:46:41.\n",
            "  Batch 28,500  of  35,790.    Elapsed: 0:47:31.\n",
            "  Batch 29,000  of  35,790.    Elapsed: 0:48:21.\n",
            "  Batch 29,500  of  35,790.    Elapsed: 0:49:11.\n",
            "  Batch 30,000  of  35,790.    Elapsed: 0:50:01.\n",
            "  Batch 30,500  of  35,790.    Elapsed: 0:50:50.\n",
            "  Batch 31,000  of  35,790.    Elapsed: 0:51:40.\n",
            "  Batch 31,500  of  35,790.    Elapsed: 0:52:30.\n",
            "  Batch 32,000  of  35,790.    Elapsed: 0:53:20.\n",
            "  Batch 32,500  of  35,790.    Elapsed: 0:54:10.\n",
            "  Batch 33,000  of  35,790.    Elapsed: 0:55:00.\n",
            "  Batch 33,500  of  35,790.    Elapsed: 0:55:50.\n",
            "  Batch 34,000  of  35,790.    Elapsed: 0:56:39.\n",
            "  Batch 34,500  of  35,790.    Elapsed: 0:57:29.\n",
            "  Batch 35,000  of  35,790.    Elapsed: 0:58:19.\n",
            "  Batch 35,500  of  35,790.    Elapsed: 0:59:09.\n",
            "\n",
            "  Average Data loss: 0.37\n",
            "  Training epcoh took: 0:59:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:01:53\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  35,790.    Elapsed: 0:00:51.\n",
            "  Batch 1,000  of  35,790.    Elapsed: 0:01:43.\n",
            "  Batch 1,500  of  35,790.    Elapsed: 0:02:33.\n",
            "  Batch 2,000  of  35,790.    Elapsed: 0:03:23.\n",
            "  Batch 2,500  of  35,790.    Elapsed: 0:04:13.\n",
            "  Batch 3,000  of  35,790.    Elapsed: 0:05:04.\n",
            "  Batch 3,500  of  35,790.    Elapsed: 0:05:54.\n",
            "  Batch 4,000  of  35,790.    Elapsed: 0:06:44.\n",
            "  Batch 4,500  of  35,790.    Elapsed: 0:07:35.\n",
            "  Batch 5,000  of  35,790.    Elapsed: 0:08:25.\n",
            "  Batch 5,500  of  35,790.    Elapsed: 0:09:16.\n",
            "  Batch 6,000  of  35,790.    Elapsed: 0:10:06.\n",
            "  Batch 6,500  of  35,790.    Elapsed: 0:10:56.\n",
            "  Batch 7,000  of  35,790.    Elapsed: 0:11:47.\n",
            "  Batch 7,500  of  35,790.    Elapsed: 0:12:37.\n",
            "  Batch 8,000  of  35,790.    Elapsed: 0:13:28.\n",
            "  Batch 8,500  of  35,790.    Elapsed: 0:14:18.\n",
            "  Batch 9,000  of  35,790.    Elapsed: 0:15:08.\n",
            "  Batch 9,500  of  35,790.    Elapsed: 0:15:57.\n",
            "  Batch 10,000  of  35,790.    Elapsed: 0:16:47.\n",
            "  Batch 10,500  of  35,790.    Elapsed: 0:17:37.\n",
            "  Batch 11,000  of  35,790.    Elapsed: 0:18:26.\n",
            "  Batch 11,500  of  35,790.    Elapsed: 0:19:16.\n",
            "  Batch 12,000  of  35,790.    Elapsed: 0:20:06.\n",
            "  Batch 12,500  of  35,790.    Elapsed: 0:20:56.\n",
            "  Batch 13,000  of  35,790.    Elapsed: 0:21:45.\n",
            "  Batch 13,500  of  35,790.    Elapsed: 0:22:35.\n",
            "  Batch 14,000  of  35,790.    Elapsed: 0:23:25.\n",
            "  Batch 14,500  of  35,790.    Elapsed: 0:24:14.\n",
            "  Batch 15,000  of  35,790.    Elapsed: 0:25:04.\n",
            "  Batch 15,500  of  35,790.    Elapsed: 0:25:54.\n",
            "  Batch 16,000  of  35,790.    Elapsed: 0:26:43.\n",
            "  Batch 16,500  of  35,790.    Elapsed: 0:27:33.\n",
            "  Batch 17,000  of  35,790.    Elapsed: 0:28:23.\n",
            "  Batch 17,500  of  35,790.    Elapsed: 0:29:12.\n",
            "  Batch 18,000  of  35,790.    Elapsed: 0:30:02.\n",
            "  Batch 18,500  of  35,790.    Elapsed: 0:30:53.\n",
            "  Batch 19,000  of  35,790.    Elapsed: 0:31:44.\n",
            "  Batch 19,500  of  35,790.    Elapsed: 0:32:33.\n",
            "  Batch 20,000  of  35,790.    Elapsed: 0:33:23.\n",
            "  Batch 20,500  of  35,790.    Elapsed: 0:34:13.\n",
            "  Batch 21,000  of  35,790.    Elapsed: 0:35:02.\n",
            "  Batch 21,500  of  35,790.    Elapsed: 0:35:52.\n",
            "  Batch 22,000  of  35,790.    Elapsed: 0:36:43.\n",
            "  Batch 22,500  of  35,790.    Elapsed: 0:37:33.\n",
            "  Batch 23,000  of  35,790.    Elapsed: 0:38:23.\n",
            "  Batch 23,500  of  35,790.    Elapsed: 0:39:14.\n",
            "  Batch 24,000  of  35,790.    Elapsed: 0:40:04.\n",
            "  Batch 24,500  of  35,790.    Elapsed: 0:40:54.\n",
            "  Batch 25,000  of  35,790.    Elapsed: 0:41:44.\n",
            "  Batch 25,500  of  35,790.    Elapsed: 0:42:34.\n",
            "  Batch 26,000  of  35,790.    Elapsed: 0:43:24.\n",
            "  Batch 26,500  of  35,790.    Elapsed: 0:44:15.\n",
            "  Batch 27,000  of  35,790.    Elapsed: 0:45:05.\n",
            "  Batch 27,500  of  35,790.    Elapsed: 0:45:54.\n",
            "  Batch 28,000  of  35,790.    Elapsed: 0:46:44.\n",
            "  Batch 28,500  of  35,790.    Elapsed: 0:47:34.\n",
            "  Batch 29,000  of  35,790.    Elapsed: 0:48:23.\n",
            "  Batch 29,500  of  35,790.    Elapsed: 0:49:13.\n",
            "  Batch 30,000  of  35,790.    Elapsed: 0:50:03.\n",
            "  Batch 30,500  of  35,790.    Elapsed: 0:50:52.\n",
            "  Batch 31,000  of  35,790.    Elapsed: 0:51:42.\n",
            "  Batch 31,500  of  35,790.    Elapsed: 0:52:32.\n",
            "  Batch 32,000  of  35,790.    Elapsed: 0:53:22.\n",
            "  Batch 32,500  of  35,790.    Elapsed: 0:54:11.\n",
            "  Batch 33,000  of  35,790.    Elapsed: 0:55:01.\n",
            "  Batch 33,500  of  35,790.    Elapsed: 0:55:51.\n",
            "  Batch 34,000  of  35,790.    Elapsed: 0:56:41.\n",
            "  Batch 34,500  of  35,790.    Elapsed: 0:57:30.\n",
            "  Batch 35,000  of  35,790.    Elapsed: 0:58:20.\n",
            "  Batch 35,500  of  35,790.    Elapsed: 0:59:10.\n",
            "\n",
            "  Average Data loss: 0.33\n",
            "  Training epcoh took: 0:59:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:01:53\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(df_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(df_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_df_loss = total_loss / len(df_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average Data loss: {0:.2f}\".format(avg_df_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():\n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # 출력 로짓 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88dfe2f0-19a5-4524-8fb5-11539c5e4ebc",
      "metadata": {
        "id": "88dfe2f0-19a5-4524-8fb5-11539c5e4ebc"
      },
      "outputs": [],
      "source": [
        "##### 예를 들어,\n",
        "##### from transformers import BertForMaskedLM, TFAutoModelWithLMHead\n",
        "\n",
        "##### torch_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "##### tf_model = TFAutoModelWithLMHead.from_pretrained(\"t5-small\")\n",
        "\n",
        "# 모델 저장 방법 : save_pretrained(디렉토리)\n",
        "# 모델을 저장하는 방법은 save_pretrained 함수 내에 원하는 디렉토리를 input으로 적어주시면 저장이 완료\n",
        "# 파이토치 기반 모델은 pt 확장자를, 텐서플로우 기반 모델은 h5 확장자로 지정\n",
        "# 모델 저장 변수 이름.save_pretrained(원하는 디렉토리) 형태\n",
        "\n",
        "# torch_model.save_pretrained('model.pt') # 파이토치 기반 모델\n",
        "# tf_model.save_pretrained('model.h5') # 텐서플로우 기반 모델\n",
        "\n",
        "# 모델 불러오기 방법 : from_pretrained(디렉토리)\n",
        "# 모델 클래스 이름.from_pretrained() 메소드로 가져오면 됩니다. 이 때, input으로 모델이 저장된 파일의 디렉토리를 적어주셔야 합니다.\n",
        "# 모델 클래스 이름.from_pretrained(저장된 디렉토리) 형태\n",
        "\n",
        "# tf_model = BertForMaskedLM.from_pretrained('/home/hyunkoo/DATA/Uhyeon/data_whole_model.pt')\n",
        "# tf_model = TFAutoModelWithLMHead.from_pretrained('/home/hyunkoo/DATA/Uhyeon/data_whole_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2109022-682a-47ab-bb08-1a9289214a65",
      "metadata": {
        "id": "b2109022-682a-47ab-bb08-1a9289214a65"
      },
      "outputs": [],
      "source": [
        "# 모델 저장 방법 : save_pretrained(디렉토리)\n",
        "# 모델 저장 변수 이름.save_pretrained(원하는 디렉토리) 형태\n",
        "\n",
        "model_test.save_pretrained('/home/hyunkoo/DATA/Uhyeon/data_whole_model_test.pt') # 파이토치 기반 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86cc1c1d-fddd-4241-b267-38fd0112a40d",
      "metadata": {
        "id": "86cc1c1d-fddd-4241-b267-38fd0112a40d"
      },
      "outputs": [],
      "source": [
        "# 모델 불러오기 방법 : from_pretrained(디렉토리)\n",
        "# 모델 클래스 이름.from_pretrained(저장된 디렉토리) 형태\n",
        "model_test = BertForSequenceClassification.from_pretrained('/home/hyunkoo/DATA/Uhyeon/data_whole_model_test.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0b00667-cac4-491a-b2ce-528a6005761d",
      "metadata": {
        "id": "f0b00667-cac4-491a-b2ce-528a6005761d",
        "outputId": "4d1a1a55-f4fd-46d6-8e9e-78221cfa4492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트셋 평가"
      ],
      "metadata": {
        "id": "cbIDoceXytzR"
      },
      "id": "cbIDoceXytzR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4347fa7-4ede-4771-bd4d-77bfb784a54f",
      "metadata": {
        "id": "f4347fa7-4ede-4771-bd4d-77bfb784a54f"
      },
      "outputs": [],
      "source": [
        "##### 테스트셋 - 전처리 #####\n",
        "\n",
        "##### 테스트셋 - 평가 #####\n",
        "\n",
        "# # 시작 시간 설정\n",
        "# t0 = time.time()\n",
        "\n",
        "# # 평가모드로 변경\n",
        "# model.eval()\n",
        "\n",
        "# # 변수 초기화\n",
        "# eval_loss, eval_accuracy = 0, 0\n",
        "# nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "# for step, batch in enumerate(test_dataloader):\n",
        "#     # 경과 정보 표시\n",
        "#     if step % 100 == 0 and not step == 0:\n",
        "#         elapsed = format_time(time.time() - t0)\n",
        "#         print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "#     # 배치를 GPU에 넣음\n",
        "#     batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "#     # 배치에서 데이터 추출\n",
        "#     b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "#     # 그래디언트 계산 안함\n",
        "#     with torch.no_grad():\n",
        "#         # Forward 수행\n",
        "#         outputs = model(b_input_ids,\n",
        "#                         token_type_ids=None,\n",
        "#                         attention_mask=b_input_mask)\n",
        "\n",
        "#     # 출력 로짓 구함\n",
        "#     logits = outputs[0]\n",
        "\n",
        "#     # CPU로 데이터 이동\n",
        "#     logits = logits.detach().cpu().numpy()\n",
        "#     label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "#     # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "#     tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "#     eval_accuracy += tmp_eval_accuracy\n",
        "#     nb_eval_steps += 1\n",
        "\n",
        "# print(\"\")\n",
        "# print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "# print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4caf4b4-5b2a-4b99-a322-28d0437ede10",
      "metadata": {
        "id": "c4caf4b4-5b2a-4b99-a322-28d0437ede10"
      },
      "outputs": [],
      "source": [
        "##### 새로운 문장 테스트 #####\n",
        "model.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "# CPU를 사용합니다.\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# 입력 문장을 토큰화하고 BERT 모델에 맞게 변환하는 함수를 정의합니다.\n",
        "def convert_input_data(sentences):\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "    MAX_LEN = 450\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    inputs = torch.tensor(input_ids).to(device)  # 입력 데이터를 CPU로 이동\n",
        "    masks = torch.tensor(attention_masks).to(device)  # 어텐션 마스크를 CPU로 이동\n",
        "    return inputs, masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31710440-0073-4c90-a4f1-d87cb3ed223f",
      "metadata": {
        "id": "31710440-0073-4c90-a4f1-d87cb3ed223f"
      },
      "outputs": [],
      "source": [
        "# 문장을 테스트하는 함수를 정의합니다.\n",
        "def test_sentences(sentences):\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, token_type_ids=None, attention_mask=masks)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    probabilities = probabilities.numpy()\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dd3a679-3d0a-4c62-8bfb-b316bee9e994",
      "metadata": {
        "id": "9dd3a679-3d0a-4c62-8bfb-b316bee9e994",
        "outputId": "8da666d4-4852-4871-9748-788c3ded0267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 오늘부터 수업 방해 시 '분리'…휴대폰도 압수 가능 [SEP]\n",
            "\n",
            "검찰이 화천대유 대주주 김만배씨가 지난 대선 당시 '허위 인터뷰'의 대가로 신학림 전 언론노조위원장에게 금품을 제공한 정황을 포착해 수사에 나섰습니다.\n",
            "서울중앙지검 반부패수사3부(부장검사 강백신)는 오늘 오전부터 배임수·증재 및 청탁금지법 위반 혐의로 신 전 위원장의 자택과 사무실 등을 압수수색하고 있습니다.\n",
            "검찰은 전달한 돈이 1억원대로 보고 있습니다.\n",
            "김만배씨와 신 전 위원장의 인터뷰는 지난 대선을 사흘 남겨둔 2022년 3월 6일 뉴스타파를 통해 공개됐습니다.\n",
            "뉴스타파는 전문위원으로 있던 신 전 위원장과 김씨가 지난 2021년 9월 15일 나눈 육성 대화라며 해당 내용을 온라인에 게시했습니다.\n",
            "해당 인터뷰에는 김씨가 \"(윤석열 검사가)커피 한 잔 주면서 '응, 얘기 다 들었어. 들었지? 가, 임마' 이러면서 보내더래. 그래서 사건이 없어졌어\"라고 주장하는 등 당시 야권 후보였던 윤석열 후보가 검사 시절 부산저축은행 '대출 브로커' 조우형씨의 수사를 무마해줬다는 내용이 담겼습니다.\n",
            "이를 두고 민주당 측에서 \"대장동 몸통은 윤석열\"이라며 공세를 펼쳤고, 국민의힘은 \"명백한 허위사실\"이라고 맞받으며 논란이 불거졌습니다.\n",
            "하지만 검찰은 인터뷰를 거짓으로 한 뒤,\n",
            "인터뷰 직후 김씨가 신 전 위원장에게 1억원대의 금품을 준 것으로 의심하고 있습니다. [SEP]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 파일에서 텍스트를 읽어오는 함수를 정의합니다\n",
        "def read_text_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "###### 네이버 뉴스에서 실제 기사를 가져와서 테스트 해보기\n",
        "\n",
        "###### Test 01 가짜 뉴스 테스트 ######\n",
        "file_path = '/home/hyunkoo/DATA/Uhyeon/news_test_01.txt'\n",
        "\n",
        "# 파일에서 텍스트를 읽어옵니다\n",
        "news_test_01 = read_text_from_file(file_path)\n",
        "print(news_test_01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d7819b9-8a9f-4267-8cd1-a67e07469050",
      "metadata": {
        "id": "8d7819b9-8a9f-4267-8cd1-a67e07469050",
        "outputId": "b0184b5c-1b17-4d2d-ec37-1697ee7397ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.99784565 0.00215431]]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 모델을 사용하여 텍스트의 유사도를 테스트합니다\n",
        "###### Test 01 가짜 뉴스 테스트 => 결과 0 출력되어야 함\n",
        "logits = test_sentences([news_test_01])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6f4808-39bf-49fd-b11a-1b130e39b932",
      "metadata": {
        "id": "3d6f4808-39bf-49fd-b11a-1b130e39b932",
        "outputId": "82a2e734-893d-455e-cffc-096b0a73c4b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 교사들은 집에서 재택근무한다 [SEP]\n",
            "\n",
            "1일부터 교권 확립 및 학생의 학습권 보호를 위한 '교원의 학생생활지도에 관한 고시'와 '유치원 교원의 교육활동 보호를 위한 고시'가 교육 현장에 적용된다. 이에 따라 교사들은 수업을 방해하는 학생을 교실 밖으로 내보내고 휴대전화도 압수할 수 있게 된다. 지금까지는 학생이 수업 중 휴대전화를 사용해도 교원이 이를 제지할 근거가 부족했지만 이날부터 긴급 상황을 제외하고는 수업 중 휴대전화 사용이 금지된다. 교원은 이를 지키지 않는 학생에게 '주의'를 줄 수 있으며, 학생이 불응한다면 휴대전화를 압수해 보관할 수 있다. [SEP]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "###### 네이버 뉴스에서 실제 기사를 가져와서 테스트 해보기\n",
        "\n",
        "###### Test 02 가짜 뉴스 테스트 ######\n",
        "file_path = '/home/hyunkoo/DATA/Uhyeon/news_test_02.txt'\n",
        "\n",
        "# 파일에서 텍스트를 읽어옵니다\n",
        "news_test_02 = read_text_from_file(file_path)\n",
        "print(news_test_02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811619ce-49a3-49e1-82f5-286e5d043360",
      "metadata": {
        "id": "811619ce-49a3-49e1-82f5-286e5d043360",
        "outputId": "bb3be708-5e5a-4ef0-e120-c5e14a97a12a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.8307905 0.1692095]]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 모델을 사용하여 텍스트의 유사도를 테스트합니다\n",
        "###### Test 02 가짜 뉴스 테스트 => 결과 0 출력되어야 함\n",
        "logits = test_sentences([news_test_02])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39c76e1-facd-412b-8012-dfdb4edcbab3",
      "metadata": {
        "id": "a39c76e1-facd-412b-8012-dfdb4edcbab3",
        "outputId": "2b2eaaf8-5ab4-43f0-a527-2b71ee876e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 제트스키 타던 모로코 관광객, 실수로 국경 넘어 '총격 사망' [SEP]\n",
            "\n",
            "북아프리카 모로코에서 제트스키를 타던 관광객 2명이 실수로 해상 국경을 넘어 알제리 해안경비대의 총을 맞고 숨진 것으로 전해졌습니다.\n",
            "1일(현지시간) BBC 등 외신에 따르면 사건은 지난달 29일 모로코 해변 휴양지인 사이디아에서 발생했습니다.\n",
            "사고를 당한 이들은 프랑스-모로코 이중국적자로, 총 4명의 일행이 휴가를 즐기고 있었습니다. 이들은 형제 및 친구 관계인 것으로 전해졌습니다.\n",
            "이들은 다 함께 제트스키를 타던 중 파도에 휩쓸려 길을 잃었습니다. 이 과정에서 해상 국경을 넘게 됐고, 이 모습은 알제리 해안경비대에 포착됐습니다.\n",
            "4명 중 2명은 알제리 해안경비대가 쏜 총에 맞아 숨졌고, 1명은 체포됐습니다. 또 다른 1명은 현장을 피해 사이디아 해변으로 도망쳐 살아남았습니다. [SEP]\n",
            " \n"
          ]
        }
      ],
      "source": [
        "###### 네이버 뉴스에서 실제 기사를 가져와서 테스트 해보기\n",
        "\n",
        "###### Test 03 진짜 뉴스 테스트 ######\n",
        "file_path = '/home/hyunkoo/DATA/Uhyeon/news_test_03.txt'\n",
        "\n",
        "# 파일에서 텍스트를 읽어옵니다\n",
        "news_test_03 = read_text_from_file(file_path)\n",
        "print(news_test_03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239e587d-185d-4d8b-9959-55dba815e4d9",
      "metadata": {
        "id": "239e587d-185d-4d8b-9959-55dba815e4d9",
        "outputId": "fb435d6f-6b5d-418a-bea5-4674b3131256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.87444365 0.12555633]]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 모델을 사용하여 텍스트의 유사도를 테스트합니다\n",
        "###### Test 03 진짜 뉴스 테스트 => 결과 1 출력되어야 함\n",
        "logits = test_sentences([news_test_03])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fb9a6f-ad18-4323-b6a9-724bcd09ae5e",
      "metadata": {
        "id": "f0fb9a6f-ad18-4323-b6a9-724bcd09ae5e",
        "outputId": "f3c64c8a-fb85-41e7-9d36-7470f63a22a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "가짜뉴스_Class_0_Index 0:\n",
            "Probabilities: [[0.99874544 0.00125454]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 6:\n",
            "Probabilities: [[0.98483306 0.01516697]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 12:\n",
            "Probabilities: [[0.9987565  0.00124342]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 17:\n",
            "Probabilities: [[0.99875534 0.00124462]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 20:\n",
            "Probabilities: [[0.9987207  0.00127922]]\n",
            "Predicted Class: 0\n",
            "진짜뉴스_class_1_Index 1:\n",
            "Probabilities: [[0.01665999 0.98334   ]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 2:\n",
            "Probabilities: [[0.01772212 0.98227787]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 3:\n",
            "Probabilities: [[0.00835113 0.9916489 ]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 4:\n",
            "Probabilities: [[0.00660365 0.9933963 ]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 5:\n",
            "Probabilities: [[0.01187915 0.9881209 ]]\n",
            "Predicted Class: 1\n"
          ]
        }
      ],
      "source": [
        "###### (이슈) 네이버 뉴스에서 실제 기사로 테스트 해본 결과 분류가 제대로 되지 않는 문제 발생 => 결과가 모두 \"진짜뉴스 Class 1\" 으로 나옴\n",
        "###### 기존에 학습한 Train 데이터에서 가짜뉴스 5개, 진짜뉴스 5개를 가져와서 분류가 제대로 되는지 확인\n",
        "\n",
        "# 가짜뉴스 : Class 0 데이터 인덱스\n",
        "class_0_indices = [0, 6, 12, 17, 20]\n",
        "for index in class_0_indices:\n",
        "    # [CLS] + Headline + [SEP] + Content + [SEP]로 조합\n",
        "    sentences = [\"[CLS] \" + df['Headline'][index] + \" [SEP] \" + df['Content'][index] + \" [SEP]\"]\n",
        "    logits = test_sentences(sentences)\n",
        "    print(f\"가짜뉴스_Class_0_Index {index}:\")\n",
        "    print(\"Probabilities:\", logits)\n",
        "    print(\"Predicted Class:\", np.argmax(logits))\n",
        "\n",
        "# 진짜뉴스 : Class 1 데이터 인덱스\n",
        "class_1_indices = [1, 2, 3, 4, 5]\n",
        "for index in class_1_indices:\n",
        "    # [CLS] + Headline + [SEP] + Content + [SEP]로 조합\n",
        "    sentences = [\"[CLS] \" + df['Headline'][index] + \" [SEP] \" + df['Content'][index] + \" [SEP]\"]\n",
        "    logits = test_sentences(sentences)\n",
        "    print(f\"진짜뉴스_class_1_Index {index}:\")\n",
        "    print(\"Probabilities:\", logits)\n",
        "    print(\"Predicted Class:\", np.argmax(logits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c52a759-0076-4d8c-b4cd-ee626dcd43d2",
      "metadata": {
        "id": "2c52a759-0076-4d8c-b4cd-ee626dcd43d2"
      },
      "outputs": [],
      "source": [
        "###### 학습된 기존 모델을 불러와서 테스트 해보기 ######\n",
        "\n",
        "# !pip install transformers\n",
        "# !pip install tensorflow\n",
        "# !pip install torch\n",
        "# !pip install -U scikit-learn\n",
        "# !pip install pandas numpy\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import torch\n",
        "\n",
        "# from transformers import BertTokenizer\n",
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import time\n",
        "# import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0359c8-575f-4573-90f3-d20c9e1c9e96",
      "metadata": {
        "id": "fa0359c8-575f-4573-90f3-d20c9e1c9e96",
        "outputId": "516ea7af-37eb-4377-840d-02526e95a3c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "가짜뉴스_Class_0_Index 0:\n",
            "Probabilities: [[0.99874544 0.00125454]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 6:\n",
            "Probabilities: [[0.98483306 0.01516697]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 12:\n",
            "Probabilities: [[0.9987565  0.00124342]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 17:\n",
            "Probabilities: [[0.99875534 0.00124462]]\n",
            "Predicted Class: 0\n",
            "가짜뉴스_Class_0_Index 20:\n",
            "Probabilities: [[0.9987207  0.00127922]]\n",
            "Predicted Class: 0\n",
            "진짜뉴스_class_1_Index 1:\n",
            "Probabilities: [[0.01665999 0.98334   ]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 2:\n",
            "Probabilities: [[0.01772212 0.98227787]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 3:\n",
            "Probabilities: [[0.00835113 0.9916489 ]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 4:\n",
            "Probabilities: [[0.00660365 0.9933963 ]]\n",
            "Predicted Class: 1\n",
            "진짜뉴스_class_1_Index 5:\n",
            "Probabilities: [[0.01187915 0.9881209 ]]\n",
            "Predicted Class: 1\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "df = pd.read_csv('/home/hyunkoo/DATA/Uhyeon/data_whole.csv', encoding='utf-8')\n",
        "\n",
        "# BERT 토크나이저를 로드합니다.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "\n",
        "# 저장된 모델을 로드합니다.\n",
        "model = BertForSequenceClassification.from_pretrained('/home/hyunkoo/DATA/Uhyeon/data_whole_model.pt')\n",
        "\n",
        "# 입력 문장을 토큰화하고 BERT 모델에 맞게 변환하는 함수를 정의합니다.\n",
        "def convert_input_data(sentences):\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "    MAX_LEN = 450\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "    return inputs, masks\n",
        "\n",
        "# 문장을 테스트하는 함수를 정의합니다.\n",
        "def test_sentences(sentences):\n",
        "    model.eval()\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    probabilities = probabilities.cpu().numpy()\n",
        "    return probabilities\n",
        "\n",
        "# 가짜 뉴스 및 진짜 뉴스의 인덱스를 정의합니다.\n",
        "class_0_indices = [0, 6, 12, 17, 20]  # 가짜 뉴스\n",
        "class_1_indices = [1, 2, 3, 4, 5]    # 진짜 뉴스\n",
        "\n",
        "# 가짜 뉴스 테스트\n",
        "for index in class_0_indices:\n",
        "    sentences = [\"[CLS] \" + df['Headline'][index] + \" [SEP] \" + df['Content'][index] + \" [SEP]\"]\n",
        "    logits = test_sentences(sentences)\n",
        "    print(f\"가짜뉴스_Class_0_Index {index}:\")\n",
        "    print(\"Probabilities:\", logits)\n",
        "    print(\"Predicted Class:\", np.argmax(logits))\n",
        "\n",
        "# 진짜 뉴스 테스트\n",
        "for index in class_1_indices:\n",
        "    sentences = [\"[CLS] \" + df['Headline'][index] + \" [SEP] \" + df['Content'][index] + \" [SEP]\"]\n",
        "    logits = test_sentences(sentences)\n",
        "    print(f\"진짜뉴스_class_1_Index {index}:\")\n",
        "    print(\"Probabilities:\", logits)\n",
        "    print(\"Predicted Class:\", np.argmax(logits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c06194-3600-4663-b4aa-4de22348b32b",
      "metadata": {
        "id": "a4c06194-3600-4663-b4aa-4de22348b32b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}